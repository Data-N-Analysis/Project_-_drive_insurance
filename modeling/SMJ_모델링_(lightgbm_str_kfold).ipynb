{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sminjoo/Project_ORI-Team_drive_insurance/blob/main/modeling/SMJ_%EB%AA%A8%EB%8D%B8%EB%A7%81_(lightgbm_str_kfold).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp5EgxoJcfUt",
        "outputId": "67837be1-cf49-457d-b028-e1588b52635a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIAYhkb3lfRr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/보험대회/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/보험대회/test.csv')\n",
        "submission = pd.read_csv('/content/drive/MyDrive/보험대회/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train2= pd.read_csv('/content/drive/MyDrive/보험대회/train2.csv')"
      ],
      "metadata": {
        "id": "-vpIeKxU8gSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1gxjn5bmiKJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train3= pd.concat([train, train2])"
      ],
      "metadata": {
        "id": "t0fffJLF904s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG09nKwArEWv"
      },
      "outputs": [],
      "source": [
        "train3.drop('id', axis=1, inplace=True)\n",
        "test.drop('id', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRRvodjtoDSh"
      },
      "outputs": [],
      "source": [
        "gender = {'Male':0, 'Female':1}\n",
        "vehicle_Age = {'< 1 Year' : 0, '1-2 Year' : 1, '> 2 Years' : 2}\n",
        "vehicle_Damage = {'No' :0, 'Yes':1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w_FKSO9qdyY"
      },
      "outputs": [],
      "source": [
        "for df_ls in [train3, test]:\n",
        "  df_ls.replace({\"Gender\": gender}, inplace=True)\n",
        "  df_ls.replace({\"Vehicle_Age\": vehicle_Age}, inplace=True)\n",
        "  df_ls.replace({\"Vehicle_Damage\": vehicle_Damage}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "columns_to_scale = ['Age', 'Annual_Premium', 'Vintage']\n",
        "\n",
        "train3[columns_to_scale] = scaler.fit_transform(train3[columns_to_scale])\n",
        "test[columns_to_scale] = scaler.transform(test[columns_to_scale])"
      ],
      "metadata": {
        "id": "rgCYXrWxj2d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train3[\"car_sum\"] = train3[\"Vehicle_Damage\"].astype(\"str\") + train3[\"Driving_License\"].astype(\"str\") + train3[\"Previously_Insured\"].astype(\"str\")\n",
        "train3[\"car_sum\"] = train3[\"car_sum\"].astype(\"category\").cat.codes\n",
        "\n",
        "test[\"car_sum\"] = test[\"Vehicle_Damage\"].astype(\"str\") + test[\"Driving_License\"].astype(\"str\") + test[\"Previously_Insured\"].astype(\"str\")\n",
        "test[\"car_sum\"] = test[\"car_sum\"].astype(\"category\").cat.codes"
      ],
      "metadata": {
        "id": "nmt3O4h7_dk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKRny2DUtaYD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "39f754e8-2bf1-4b58-d7e5-cb1e5781c12f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Gender       Age  Driving_License  Region_Code  Previously_Insured  \\\n",
              "0       0  0.015385                1         35.0                   0   \n",
              "1       0  0.353846                1         28.0                   0   \n",
              "2       1  0.076923                1         14.0                   1   \n",
              "3       1  0.230769                1          1.0                   0   \n",
              "4       1  0.246154                1         15.0                   1   \n",
              "\n",
              "   Vehicle_Age  Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  \\\n",
              "0            1               1        0.116218                 124.0   \n",
              "1            2               1        0.104702                  26.0   \n",
              "2            0               0        0.065880                 152.0   \n",
              "3            1               1        0.000000                 156.0   \n",
              "4            1               0        0.054547                 152.0   \n",
              "\n",
              "    Vintage  Response  car_sum  \n",
              "0  0.612457         0        6  \n",
              "1  0.961938         1        6  \n",
              "2  0.844291         0        3  \n",
              "3  0.228374         0        6  \n",
              "4  0.982699         0        3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74b6d6fc-efb4-4dd3-93ff-e324a899fa69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Driving_License</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Previously_Insured</th>\n",
              "      <th>Vehicle_Age</th>\n",
              "      <th>Vehicle_Damage</th>\n",
              "      <th>Annual_Premium</th>\n",
              "      <th>Policy_Sales_Channel</th>\n",
              "      <th>Vintage</th>\n",
              "      <th>Response</th>\n",
              "      <th>car_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.015385</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.116218</td>\n",
              "      <td>124.0</td>\n",
              "      <td>0.612457</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.353846</td>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.104702</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.961938</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.065880</td>\n",
              "      <td>152.0</td>\n",
              "      <td>0.844291</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>156.0</td>\n",
              "      <td>0.228374</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.246154</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.054547</td>\n",
              "      <td>152.0</td>\n",
              "      <td>0.982699</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74b6d6fc-efb4-4dd3-93ff-e324a899fa69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74b6d6fc-efb4-4dd3-93ff-e324a899fa69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74b6d6fc-efb4-4dd3-93ff-e324a899fa69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dd1fa35f-344e-49f1-86ab-7f09063c82e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd1fa35f-344e-49f1-86ab-7f09063c82e9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dd1fa35f-344e-49f1-86ab-7f09063c82e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train3"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train3.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = train3.drop('Response', axis=1)\n",
        "y = train3['Response']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "j_ylNHAYRYoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 1) 검색 공간 설정\n",
        "\n",
        "from hyperopt import hp\n",
        "\n",
        "## LightGBM이 XBGoost에 비해 깊이가 깊음\n",
        "lgbm_search_space = {\n",
        "    'num_leaves':hp.quniform('num_leaves', 32, 64, 1),\n",
        "    'max_depth':hp.quniform('max_depth', 100, 169, 1),                  ## 정수형 하이퍼 파라미터 => quniform 사용\n",
        "    'min_child_weight':hp.quniform('min_child_weight', 60, 100, 1),     ## 정수형 하이퍼 파라미터 => quniform 사용\n",
        "    'learning_rate':hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    'subsample':hp.uniform('subsample', 0.7, 1),\n",
        "}\n",
        "\n",
        "## 2) 목적 함수 설정\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "def objective_func(search_space):\n",
        "\n",
        "  lgbm_clf = LGBMClassifier(\n",
        "      n_estimators=100,\n",
        "      max_depth=int(search_space['max_depth']),                ## int형으로 형변환 필요\n",
        "      min_child_weight=int(search_space['min_child_weight']),  ## int형으로 형변환 필요\n",
        "      learning_rate=search_space['learning_rate'],\n",
        "      subsample=search_space['subsample'],\n",
        "      num_leaves=int(search_space['num_leaves']),\n",
        "      #eval_metric='logloss' => 불균형 데이터셋이므로 성능 평가 지표를 roc-auc로 설정\n",
        "      )\n",
        "\n",
        "      ## XGBoost와 LightGBM에서는 cross_val_score()를 적용하면 early stopping 지원 불가, KFold 방식으로 직접 구현해야 함\n",
        "      ## 3개의 k-fold 방식으로 평가된 roc-auc 지표를 담는 list\n",
        "  roc_auc_list = []\n",
        "\n",
        "  ## 3개의 Stratified k-fold 방식 적용\n",
        "  skf = StratifiedKFold(n_splits=3)\n",
        "\n",
        "  for tr_index, val_index in skf.split(X_train, y_train):\n",
        "\n",
        "    X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
        "    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
        "\n",
        "    lgbm_clf.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_metric='auc',\n",
        "        eval_set=[(X_tr, y_tr), (X_val, y_val)]\n",
        "    )\n",
        "\n",
        "    score = roc_auc_score(\n",
        "        y_val,\n",
        "        lgbm_clf.predict_proba(X_val)[:, 1]\n",
        "    )\n",
        "\n",
        "    roc_auc_list.append(score)\n",
        "\n",
        "  return (-1) * np.mean(roc_auc_list)\n",
        "\n",
        "## 3) fmin()을 사용하여 최적 하이퍼 파라미터 찾기\n",
        "!pip install hyperopt\n",
        "from hyperopt import fmin, tpe, Trials\n",
        "\n",
        "trials = Trials()\n",
        "\n",
        "best = fmin(\n",
        "    fn=objective_func,\n",
        "    space=lgbm_search_space,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=10,  ## 10번 만큼 반복하며 최적의 하이퍼 파라미터 찾음\n",
        "    trials=trials,\n",
        ")"
      ],
      "metadata": {
        "id": "i7ihE9KEUect",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6915f3-3aea-45fa-b237-d91347937dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n",
            "[LightGBM] [Info] Number of positive: 779694, number of negative: 5559456\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.469042 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 744\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964354\n",
            "[LightGBM] [Info] Start training from score -1.964354\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.445718 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.286852 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 750\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779694, number of negative: 5559456\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.460412 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 744\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964354\n",
            "[LightGBM] [Info] Start training from score -1.964354\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.466086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.448603 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 750\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779694, number of negative: 5559456\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.456729 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 744\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964354\n",
            "[LightGBM] [Info] Start training from score -1.964354\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.457578 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.295408 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 750\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779694, number of negative: 5559456\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.261007 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 744\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964354\n",
            "[LightGBM] [Info] Start training from score -1.964354\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.251033 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.256592 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 750\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779694, number of negative: 5559456\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.389215 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 744\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964354\n",
            "[LightGBM] [Info] Start training from score -1.964354\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.255713 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.255337 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 750\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779694, number of negative: 5559456\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.418187 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 744\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964354\n",
            "[LightGBM] [Info] Start training from score -1.964354\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.272836 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.260437 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 750\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779694, number of negative: 5559456\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.254872 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 744\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964354\n",
            "[LightGBM] [Info] Start training from score -1.964354\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.271870 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.398752 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 750\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779694, number of negative: 5559456\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.279350 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 744\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964354\n",
            "[LightGBM] [Info] Start training from score -1.964354\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.259421 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.433259 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 750\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779694, number of negative: 5559456\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.252290 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 744\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964354\n",
            "[LightGBM] [Info] Start training from score -1.964354\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.256822 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.258539 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 750\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779694, number of negative: 5559456\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.253746 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 744\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964354\n",
            "[LightGBM] [Info] Start training from score -1.964354\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.267831 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "[LightGBM] [Info] Number of positive: 779693, number of negative: 5559457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.263138 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 750\n",
            "[LightGBM] [Info] Number of data points in the train set: 6339150, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122996 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "100%|██████████| 10/10 [2:56:48<00:00, 1060.87s/trial, best loss: -0.8779688848912852]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 획득한 최적의 하이퍼 파라미터를 이용하여 모델 선언\n",
        "lgbm_wrapper = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    num_leaves=int(best['num_leaves']),\n",
        "    learning_rate=round(best['learning_rate'], 5),\n",
        "    max_depth=int(best['max_depth']),\n",
        "    min_child_weight=int(best['min_child_weight']),\n",
        "    subsample=round(best['subsample'], 5)\n",
        ")"
      ],
      "metadata": {
        "id": "OE3o7QlxPLlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "# 조기 중단 파라미터 설정\n",
        "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "early_stopping_rounds = 20\n",
        "best_score = -np.inf\n",
        "best_iteration = 0\n",
        "tolerance_rounds = 0\n",
        "\n",
        "# 반복하면서 최적의 모델 찾기\n",
        "for i in range(1, 20):  # 최대 20번까지 시도\n",
        "    lgbm_wrapper = lgb.LGBMClassifier(n_estimators=i)\n",
        "    lgbm_wrapper.fit(X_train, y_train)\n",
        "    score = roc_auc_score(y_test, lgbm_wrapper.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    print(f\"Iteration {i}, AUC score: {score}\")\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_iteration = i\n",
        "        tolerance_rounds = 0\n",
        "    else:\n",
        "        tolerance_rounds += 1\n",
        "\n",
        "    if tolerance_rounds >= early_stopping_rounds:\n",
        "        break\n",
        "\n",
        "print(f\"Best iteration: {best_iteration}\")\n",
        "print(f\"Best score: {best_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P015bWgiGw5G",
        "outputId": "b20f1bb0-1da7-441f-80e6-c93d6e5cf7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.647916 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 1, AUC score: 0.8541042110291986\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.396868 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 2, AUC score: 0.8560032243370871\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.397595 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 3, AUC score: 0.8571398297954844\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.627325 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 4, AUC score: 0.8602919672721455\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.626900 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 5, AUC score: 0.8605889524352478\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.403386 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 6, AUC score: 0.8605805742556796\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.413887 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 7, AUC score: 0.8609662871310398\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.649164 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 8, AUC score: 0.8622177649510754\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.420432 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 9, AUC score: 0.8623785624500695\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.403815 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 10, AUC score: 0.8626728124556131\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.408407 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 11, AUC score: 0.8626925318177162\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.394226 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 12, AUC score: 0.8630889643252871\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.394630 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 13, AUC score: 0.8633243481971727\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.406363 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 14, AUC score: 0.8634917309581733\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.422735 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 15, AUC score: 0.86436033260259\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.420143 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 16, AUC score: 0.8644976734141809\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.405004 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 17, AUC score: 0.8646343439395332\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.681982 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 18, AUC score: 0.8653304857753492\n",
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.416608 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n",
            "Iteration 19, AUC score: 0.8654752964212294\n",
            "Best iteration: 19\n",
            "Best score: 0.8654752964212294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적의 n_estimators로 모델 다시 학습\n",
        "lgbm_wrapper.set_params(n_estimators=best_iteration)\n",
        "lgbm_wrapper.fit(X_train, y_train, eval_set=eval_set, eval_metric='auc')"
      ],
      "metadata": {
        "id": "dntYN8QiyFM5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "16b62577-9dff-4c92-ef58-cf337990c612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 1169540, number of negative: 8339185\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.412962 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 748\n",
            "[LightGBM] [Info] Number of data points in the train set: 9508725, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964355\n",
            "[LightGBM] [Info] Start training from score -1.964355\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(n_estimators=19)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(n_estimators=19)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(n_estimators=19)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_roc_score = roc_auc_score(\n",
        "    y_test,\n",
        "    lgbm_wrapper.predict_proba(X_test)[:, 1]\n",
        ")\n",
        "\n",
        "lgbm_roc_score"
      ],
      "metadata": {
        "id": "PZg-B5_dViDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538eba5f-306b-4918-9439-7146825e46da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8654752964212294"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = lgbm_wrapper.predict(X_test)"
      ],
      "metadata": {
        "id": "Z7ZGc457yLb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "test_input = test.values\n",
        "probabilities = lgbm_wrapper.predict_proba(test_input)\n",
        "\n",
        "second_class_probabilities = probabilities[:, 1]\n",
        "submission['Response']= second_class_probabilities\n",
        "submission.to_csv(\"/content/drive/MyDrive/보험대회/submission_lightgbm_skf.csv\", index=False)"
      ],
      "metadata": {
        "id": "sIFwo_iwyrIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#피처중요도\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from lightgbm import plot_importance\n",
        "\n",
        "\n",
        "ax = lgb.plot_importance(lgbm_wrapper, importance_type='split', max_num_features=10, figsize=(10, 6))\n",
        "plt.title('Feature Importance (Split)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CxmX_rVeXLVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['Response'].value_counts()"
      ],
      "metadata": {
        "id": "nvMgJ7bjxzSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a830cf-ccd1-474d-f3e2-ff4a51e067e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response\n",
              "0.018704    3366291\n",
              "0.041278     374105\n",
              "0.021087      73513\n",
              "0.020650      60475\n",
              "0.020952      39612\n",
              "             ...   \n",
              "0.308792          1\n",
              "0.377229          1\n",
              "0.219295          1\n",
              "0.295898          1\n",
              "0.368247          1\n",
              "Name: count, Length: 168625, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xBJLdYWm2vdNYvux1PhCzxhoSPRCFqPl",
      "authorship_tag": "ABX9TyMST9RjL7Z6hnD1xBC0taPu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}